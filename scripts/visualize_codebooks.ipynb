{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f8ac65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/audiotools/ml/layers/base.py:172: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load(location, \"cpu\")\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all codebook visualizations to 'plots/' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import dac\n",
    "\n",
    "def load_dac_model(model_type=\"44khz\", device=\"cpu\"):\n",
    "    \"\"\"Load a pretrained DAC model.\"\"\"\n",
    "    model_path = dac.utils.download(model_type=model_type)\n",
    "    model = dac.DAC.load(model_path)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def get_codebook_weights(model):\n",
    "    \"\"\"Returns a list of codebook weights: [codebook_size, codebook_dim] per codebook\"\"\"\n",
    "    return [quant.codebook.weight.detach().cpu() for quant in model.quantizer.quantizers]\n",
    "\n",
    "def tsne_project(vectors, seed=42):\n",
    "    \"\"\"Project codebook vectors into 2D using t-SNE\"\"\"\n",
    "    tsne = TSNE(n_components=2, perplexity=30, init='pca', learning_rate='auto', n_iter=1000, random_state=seed)\n",
    "    return tsne.fit_transform(vectors)\n",
    "\n",
    "def plot_codebook_2d(vectors_2d, codebook_id, save_dir=\"plots\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1], c='blue', s=20, alpha=0.7)\n",
    "    plt.title(f\"Codebook {codebook_id} — t-SNE Projection\")\n",
    "    plt.xlabel(\"Dim 1\")\n",
    "    plt.ylabel(\"Dim 2\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f\"codebook_{codebook_id}_tsne.png\"))\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    model = load_dac_model(device=\"cpu\")\n",
    "    codebook_weights = get_codebook_weights(model)\n",
    "\n",
    "    for i, vectors in enumerate(codebook_weights):\n",
    "        vectors_2d = tsne_project(vectors)\n",
    "        plot_codebook_2d(vectors_2d, codebook_id=i)\n",
    "\n",
    "    print(\"Saved all codebook visualizations to 'plots/' folder.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2259c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DAC model...\n",
      "Extracting codebook weights...\n",
      "Found 9 codebooks\n",
      "\n",
      "=== Processing Codebook 0 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 0\n",
      "\n",
      "=== Processing Codebook 1 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 1\n",
      "\n",
      "=== Processing Codebook 2 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 2\n",
      "\n",
      "=== Processing Codebook 3 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 3\n",
      "\n",
      "=== Processing Codebook 4 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 4\n",
      "\n",
      "=== Processing Codebook 5 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 5\n",
      "\n",
      "=== Processing Codebook 6 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 6\n",
      "\n",
      "=== Processing Codebook 7 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 7\n",
      "\n",
      "=== Processing Codebook 8 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 8\n",
      "\n",
      "Completed! Check the 'plots/' folder for visualizations.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN, SpectralClustering\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import dac\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings that might interfere\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "def load_dac_model(model_type=\"44khz\", device=\"cpu\"):\n",
    "    model_path = dac.utils.download(model_type=model_type)\n",
    "    model = dac.DAC.load(model_path)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_codebook_weights(model):\n",
    "    \"\"\"Returns a list of codebook weights: [codebook_size, codebook_dim] per codebook\"\"\"\n",
    "    return [quant.codebook.weight.detach().cpu().numpy() for quant in model.quantizer.quantizers]\n",
    "\n",
    "\n",
    "def simple_kmeans_numpy(X, n_clusters, max_iters=100, seed=42):\n",
    "    \"\"\"Simple K-means implementation using only numpy to avoid threading issues\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Initialize centroids randomly\n",
    "    centroids = X[np.random.choice(n_samples, n_clusters, replace=False)]\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        # Assign points to closest centroid\n",
    "        distances = np.sqrt(((X - centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "        labels = np.argmin(distances, axis=0)\n",
    "        \n",
    "        # Update centroids\n",
    "        new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(n_clusters)])\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.allclose(centroids, new_centroids):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def cluster_and_project(vectors, n_clusters=5, seed=42, method='hierarchical'):\n",
    "    \"\"\"Normalize, reduce, cluster, and project codebook vectors\"\"\"\n",
    "    print(f\"Processing {vectors.shape[0]} vectors of dimension {vectors.shape[1]}\")\n",
    "    \n",
    "    # Check if we have enough samples for clustering\n",
    "    if vectors.shape[0] < n_clusters:\n",
    "        print(f\"Warning: Only {vectors.shape[0]} vectors available, reducing clusters to {vectors.shape[0]}\")\n",
    "        n_clusters = vectors.shape[0]\n",
    "    \n",
    "    X = normalize(vectors, norm='l2')\n",
    "\n",
    "    # PCA reduction\n",
    "    n_components = min(50, X.shape[1], X.shape[0] - 1)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    print(f\"PCA reduced to {X_reduced.shape[1]} dimensions\")\n",
    "\n",
    "    # Try different clustering methods\n",
    "    print(f\"Attempting clustering with method: {method}\")\n",
    "    \n",
    "    try:\n",
    "        if method == 'hierarchical':\n",
    "            # Agglomerative clustering - no threading issues\n",
    "            clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
    "            labels = clustering.fit_predict(X_reduced)\n",
    "            print(f\"Hierarchical clustering completed with {n_clusters} clusters\")\n",
    "            \n",
    "        elif method == 'spectral':\n",
    "            # Spectral clustering\n",
    "            clustering = SpectralClustering(n_clusters=n_clusters, random_state=seed, \n",
    "                                          affinity='nearest_neighbors', n_neighbors=min(10, X_reduced.shape[0]-1))\n",
    "            labels = clustering.fit_predict(X_reduced)\n",
    "            print(f\"Spectral clustering completed with {n_clusters} clusters\")\n",
    "            \n",
    "        elif method == 'dbscan':\n",
    "            # DBSCAN - automatically determines number of clusters\n",
    "            # Estimate eps using k-distance\n",
    "            k = min(5, X_reduced.shape[0] - 1)\n",
    "            neighbors = NearestNeighbors(n_neighbors=k)\n",
    "            neighbors_fit = neighbors.fit(X_reduced)\n",
    "            distances, indices = neighbors_fit.kneighbors(X_reduced)\n",
    "            distances = np.sort(distances[:, k-1], axis=0)\n",
    "            eps = np.percentile(distances, 90)  # Use 90th percentile as eps\n",
    "            \n",
    "            clustering = DBSCAN(eps=eps, min_samples=max(2, X_reduced.shape[0] // 20))\n",
    "            labels = clustering.fit_predict(X_reduced)\n",
    "            n_clusters_found = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            print(f\"DBSCAN clustering completed with {n_clusters_found} clusters (eps={eps:.3f})\")\n",
    "            \n",
    "        elif method == 'numpy_kmeans':\n",
    "            # Simple numpy K-means implementation\n",
    "            labels = simple_kmeans_numpy(X_reduced, n_clusters, seed=seed)\n",
    "            print(f\"Numpy K-means clustering completed with {n_clusters} clusters\")\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown clustering method: {method}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Clustering method '{method}' failed with error: {e}\")\n",
    "        print(\"Falling back to simple distance-based clustering...\")\n",
    "        # Ultimate fallback: simple distance-based clustering\n",
    "        np.random.seed(seed)\n",
    "        centers = X_reduced[np.random.choice(X_reduced.shape[0], n_clusters, replace=False)]\n",
    "        distances = np.sqrt(((X_reduced - centers[:, np.newaxis])**2).sum(axis=2))\n",
    "        labels = np.argmin(distances, axis=0)\n",
    "\n",
    "    # t-SNE projection with adjusted perplexity\n",
    "    perplexity = min(30, max(5, X_reduced.shape[0] // 4))\n",
    "    print(f\"Using perplexity: {perplexity}\")\n",
    "    \n",
    "    try:\n",
    "        tsne = TSNE(\n",
    "            n_components=2, \n",
    "            perplexity=perplexity, \n",
    "            init='pca', \n",
    "            learning_rate='auto',\n",
    "            n_iter=1000, \n",
    "            random_state=seed,\n",
    "            n_jobs=1  # Force single-threaded to avoid issues\n",
    "        )\n",
    "        X_2d = tsne.fit_transform(X_reduced)\n",
    "        print(\"t-SNE projection completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"t-SNE failed with error: {e}\")\n",
    "        print(\"Falling back to PCA for 2D projection...\")\n",
    "        # Fallback: use PCA for 2D projection\n",
    "        pca_2d = PCA(n_components=2)\n",
    "        X_2d = pca_2d.fit_transform(X_reduced)\n",
    "\n",
    "    return X_2d, labels\n",
    "\n",
    "\n",
    "def plot_codebook_2d(vectors_2d, labels, codebook_id, save_dir=\"plots_heirarchical\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1], c=labels, cmap='tab10', s=30, alpha=0.7)\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.title(f\"Codebook {codebook_id} — 2D Projection with Clusters\")\n",
    "    plt.xlabel(\"Dimension 1\")\n",
    "    plt.ylabel(\"Dimension 2\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add some statistics to the plot\n",
    "    n_clusters = len(set(labels))\n",
    "    plt.text(0.02, 0.98, f'Vectors: {len(vectors_2d)}\\nClusters: {n_clusters}', \n",
    "             transform=plt.gca().transAxes, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f\"codebook_{codebook_id}_clusters.png\"), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved plot for codebook {codebook_id}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Loading DAC model...\")\n",
    "    model = load_dac_model(device=\"cpu\")\n",
    "    print(\"Extracting codebook weights...\")\n",
    "    codebook_weights = get_codebook_weights(model)\n",
    "    \n",
    "    # Try different clustering methods in order of preference\n",
    "    clustering_methods = ['hierarchical', 'numpy_kmeans', 'spectral', 'dbscan']\n",
    "    \n",
    "    print(f\"Found {len(codebook_weights)} codebooks\")\n",
    "    for i, vectors in enumerate(codebook_weights):\n",
    "        print(f\"\\n=== Processing Codebook {i} ===\")\n",
    "        print(f\"Shape: {vectors.shape}\")\n",
    "        \n",
    "        success = False\n",
    "        for method in clustering_methods:\n",
    "            try:\n",
    "                print(f\"Trying clustering method: {method}\")\n",
    "                X_2d, labels = cluster_and_project(vectors, n_clusters=5, method=method)\n",
    "                plot_codebook_2d(X_2d, labels, codebook_id=i)\n",
    "                success = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Method '{method}' failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not success:\n",
    "            print(f\"All clustering methods failed for codebook {i}\")\n",
    "\n",
    "    print(\"\\nCompleted! Check the 'plots/' folder for visualizations.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Alternative approach: Set environment variable to avoid threading issues\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cda23cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DAC model...\n",
      "Extracting codebook weights...\n",
      "Found 9 codebooks\n",
      "\n",
      "=== Processing Codebook 0 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "Saved plot for codebook 0\n",
      "\n",
      "=== Processing Codebook 1 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "Saved plot for codebook 1\n",
      "\n",
      "=== Processing Codebook 2 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "Saved plot for codebook 2\n",
      "\n",
      "=== Processing Codebook 3 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "Saved plot for codebook 3\n",
      "\n",
      "=== Processing Codebook 4 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "Saved plot for codebook 4\n",
      "\n",
      "=== Processing Codebook 5 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "Saved plot for codebook 5\n",
      "\n",
      "=== Processing Codebook 6 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "Saved plot for codebook 6\n",
      "\n",
      "=== Processing Codebook 7 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "Saved plot for codebook 7\n",
      "\n",
      "=== Processing Codebook 8 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Using perplexity: 30\n",
      "Saved plot for codebook 8\n",
      "\n",
      "Completed! Check the 'plots/' folder for visualizations.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN, SpectralClustering\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import dac\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings that might interfere\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "def load_dac_model(model_type=\"44khz\", device=\"cpu\"):\n",
    "    model_path = dac.utils.download(model_type=model_type)\n",
    "    model = dac.DAC.load(model_path)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_codebook_weights(model):\n",
    "    \"\"\"Returns a list of codebook weights: [codebook_size, codebook_dim] per codebook\"\"\"\n",
    "    return [quant.codebook.weight.detach().cpu().numpy() for quant in model.quantizer.quantizers]\n",
    "\n",
    "\n",
    "def simple_kmeans_numpy(X, n_clusters, max_iters=100, seed=42):\n",
    "    \"\"\"Simple K-means implementation using only numpy to avoid threading issues\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Initialize centroids randomly\n",
    "    centroids = X[np.random.choice(n_samples, n_clusters, replace=False)]\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        # Assign points to closest centroid\n",
    "        distances = np.sqrt(((X - centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "        labels = np.argmin(distances, axis=0)\n",
    "        \n",
    "        # Update centroids\n",
    "        new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(n_clusters)])\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.allclose(centroids, new_centroids):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def cluster_and_project(vectors, n_clusters=5, seed=42, method='hierarchical'):\n",
    "    \"\"\"Normalize, reduce, cluster, and project codebook vectors\"\"\"\n",
    "    print(f\"Processing {vectors.shape[0]} vectors of dimension {vectors.shape[1]}\")\n",
    "    \n",
    "    # Check if we have enough samples for clustering\n",
    "    if vectors.shape[0] < n_clusters:\n",
    "        print(f\"Warning: Only {vectors.shape[0]} vectors available, reducing clusters to {vectors.shape[0]}\")\n",
    "        n_clusters = vectors.shape[0]\n",
    "    \n",
    "    X = normalize(vectors, norm='l2')\n",
    "\n",
    "    # PCA reduction\n",
    "    n_components = min(50, X.shape[1], X.shape[0] - 1)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    print(f\"PCA reduced to {X_reduced.shape[1]} dimensions\")\n",
    "\n",
    "    # Try different clustering methods\n",
    "    print(f\"Attempting clustering with method: {method}\")\n",
    "    \n",
    "    try:\n",
    "        if method == 'hierarchical':\n",
    "            # Agglomerative clustering - no threading issues\n",
    "            clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
    "            labels = clustering.fit_predict(X_reduced)\n",
    "            print(f\"Hierarchical clustering completed with {n_clusters} clusters\")\n",
    "            \n",
    "        elif method == 'spectral':\n",
    "            # Spectral clustering\n",
    "            clustering = SpectralClustering(n_clusters=n_clusters, random_state=seed, \n",
    "                                          affinity='nearest_neighbors', n_neighbors=min(10, X_reduced.shape[0]-1))\n",
    "            labels = clustering.fit_predict(X_reduced)\n",
    "            print(f\"Spectral clustering completed with {n_clusters} clusters\")\n",
    "            \n",
    "        elif method == 'dbscan':\n",
    "            # DBSCAN - automatically determines number of clusters\n",
    "            # Estimate eps using k-distance\n",
    "            k = min(5, X_reduced.shape[0] - 1)\n",
    "            neighbors = NearestNeighbors(n_neighbors=k)\n",
    "            neighbors_fit = neighbors.fit(X_reduced)\n",
    "            distances, indices = neighbors_fit.kneighbors(X_reduced)\n",
    "            distances = np.sort(distances[:, k-1], axis=0)\n",
    "            eps = np.percentile(distances, 90)  # Use 90th percentile as eps\n",
    "            \n",
    "            clustering = DBSCAN(eps=eps, min_samples=max(2, X_reduced.shape[0] // 20))\n",
    "            labels = clustering.fit_predict(X_reduced)\n",
    "            n_clusters_found = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            print(f\"DBSCAN clustering completed with {n_clusters_found} clusters (eps={eps:.3f})\")\n",
    "            \n",
    "        elif method == 'numpy_kmeans':\n",
    "            # Simple numpy K-means implementation\n",
    "            labels = simple_kmeans_numpy(X_reduced, n_clusters, seed=seed)\n",
    "            print(f\"Numpy K-means clustering completed with {n_clusters} clusters\")\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown clustering method: {method}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Clustering method '{method}' failed with error: {e}\")\n",
    "        print(\"Falling back to simple distance-based clustering...\")\n",
    "        # Ultimate fallback: simple distance-based clustering\n",
    "        np.random.seed(seed)\n",
    "        centers = X_reduced[np.random.choice(X_reduced.shape[0], n_clusters, replace=False)]\n",
    "        distances = np.sqrt(((X_reduced - centers[:, np.newaxis])**2).sum(axis=2))\n",
    "        labels = np.argmin(distances, axis=0)\n",
    "\n",
    "    # t-SNE projection with adjusted perplexity\n",
    "    perplexity = min(30, max(5, X_reduced.shape[0] // 4))\n",
    "    print(f\"Using perplexity: {perplexity}\")\n",
    "    \n",
    "    pca_2d = PCA(n_components=2)\n",
    "    X_2d = pca_2d.fit_transform(X_reduced)\n",
    "\n",
    "    return X_2d, labels\n",
    "\n",
    "\n",
    "def plot_codebook_2d(vectors_2d, labels, codebook_id, save_dir=\"plots_pca\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1], c=labels, cmap='tab10', s=30, alpha=0.7)\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.title(f\"Codebook {codebook_id} — 2D Projection with Clusters\")\n",
    "    plt.xlabel(\"Dimension 1\")\n",
    "    plt.ylabel(\"Dimension 2\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add some statistics to the plot\n",
    "    n_clusters = len(set(labels))\n",
    "    plt.text(0.02, 0.98, f'Vectors: {len(vectors_2d)}\\nClusters: {n_clusters}', \n",
    "             transform=plt.gca().transAxes, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f\"codebook_{codebook_id}_clusters.png\"), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved plot for codebook {codebook_id}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Loading DAC model...\")\n",
    "    model = load_dac_model(device=\"cpu\")\n",
    "    print(\"Extracting codebook weights...\")\n",
    "    codebook_weights = get_codebook_weights(model)\n",
    "    \n",
    "    # Try different clustering methods in order of preference\n",
    "    clustering_methods = ['hierarchical', 'numpy_kmeans', 'spectral', 'dbscan']\n",
    "    \n",
    "    print(f\"Found {len(codebook_weights)} codebooks\")\n",
    "    for i, vectors in enumerate(codebook_weights):\n",
    "        print(f\"\\n=== Processing Codebook {i} ===\")\n",
    "        print(f\"Shape: {vectors.shape}\")\n",
    "        \n",
    "        success = False\n",
    "        for method in clustering_methods:\n",
    "            try:\n",
    "                print(f\"Trying clustering method: {method}\")\n",
    "                X_2d, labels = cluster_and_project(vectors, n_clusters=5, method=method)\n",
    "                plot_codebook_2d(X_2d, labels, codebook_id=i)\n",
    "                success = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Method '{method}' failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not success:\n",
    "            print(f\"All clustering methods failed for codebook {i}\")\n",
    "\n",
    "    print(\"\\nCompleted! Check the 'plots/' folder for visualizations.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Alternative approach: Set environment variable to avoid threading issues\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99c7b6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DAC model...\n",
      "Extracting codebook weights...\n",
      "Found 9 codebooks\n",
      "\n",
      "=== Processing Codebook 0 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Silhouette Score: 0.037\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 0\n",
      "\n",
      "=== Processing Codebook 1 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Silhouette Score: 0.027\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 1\n",
      "\n",
      "=== Processing Codebook 2 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Silhouette Score: 0.025\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 2\n",
      "\n",
      "=== Processing Codebook 3 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Silhouette Score: 0.025\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 3\n",
      "\n",
      "=== Processing Codebook 4 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Silhouette Score: 0.025\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 4\n",
      "\n",
      "=== Processing Codebook 5 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Silhouette Score: 0.028\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 5\n",
      "\n",
      "=== Processing Codebook 6 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Silhouette Score: 0.022\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 6\n",
      "\n",
      "=== Processing Codebook 7 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Silhouette Score: 0.019\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 7\n",
      "\n",
      "=== Processing Codebook 8 ===\n",
      "Shape: (1024, 8)\n",
      "Trying clustering method: hierarchical\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "Attempting clustering with method: hierarchical\n",
      "Hierarchical clustering completed with 5 clusters\n",
      "Silhouette Score: 0.021\n",
      "Using perplexity: 30\n",
      "t-SNE projection completed\n",
      "Saved plot for codebook 8\n",
      "\n",
      "Completed! Check the 'plots/' folder for visualizations.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN, SpectralClustering\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import dac\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings that might interfere\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "def load_dac_model(model_type=\"44khz\", device=\"cpu\"):\n",
    "    model_path = dac.utils.download(model_type=model_type)\n",
    "    model = dac.DAC.load(model_path)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_codebook_weights(model):\n",
    "    \"\"\"Returns a list of codebook weights: [codebook_size, codebook_dim] per codebook\"\"\"\n",
    "    return [quant.codebook.weight.detach().cpu().numpy() for quant in model.quantizer.quantizers]\n",
    "\n",
    "\n",
    "def simple_kmeans_numpy(X, n_clusters, max_iters=100, seed=42):\n",
    "    \"\"\"Simple K-means implementation using only numpy to avoid threading issues\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Initialize centroids randomly\n",
    "    centroids = X[np.random.choice(n_samples, n_clusters, replace=False)]\n",
    "    \n",
    "    for _ in range(max_iters):\n",
    "        # Assign points to closest centroid\n",
    "        distances = np.sqrt(((X - centroids[:, np.newaxis])**2).sum(axis=2))\n",
    "        labels = np.argmin(distances, axis=0)\n",
    "        \n",
    "        # Update centroids\n",
    "        new_centroids = np.array([X[labels == i].mean(axis=0) for i in range(n_clusters)])\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.allclose(centroids, new_centroids):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "def cluster_and_project(vectors, n_clusters=5, seed=42, method='hierarchical'):\n",
    "    \"\"\"Normalize, reduce, cluster, and project codebook vectors\"\"\"\n",
    "    print(f\"Processing {vectors.shape[0]} vectors of dimension {vectors.shape[1]}\")\n",
    "    \n",
    "    # Check if we have enough samples for clustering\n",
    "    if vectors.shape[0] < n_clusters:\n",
    "        print(f\"Warning: Only {vectors.shape[0]} vectors available, reducing clusters to {vectors.shape[0]}\")\n",
    "        n_clusters = vectors.shape[0]\n",
    "    \n",
    "    X = normalize(vectors, norm='l2')\n",
    "\n",
    "    # PCA reduction\n",
    "    n_components = min(50, X.shape[1], X.shape[0] - 1)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    print(f\"PCA reduced to {X_reduced.shape[1]} dimensions\")\n",
    "\n",
    "    # Try different clustering methods\n",
    "    print(f\"Attempting clustering with method: {method}\")\n",
    "    \n",
    "    try:\n",
    "        if method == 'hierarchical':\n",
    "            # Agglomerative clustering - no threading issues\n",
    "            clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
    "            labels = clustering.fit_predict(X_reduced)\n",
    "            print(f\"Hierarchical clustering completed with {n_clusters} clusters\")\n",
    "        \n",
    "            from sklearn.metrics import silhouette_score\n",
    "            try:\n",
    "                sil_score = silhouette_score(X_reduced, labels)\n",
    "                print(f\"Silhouette Score: {sil_score:.3f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Silhouette score calculation failed: {e}\")\n",
    "            \n",
    "        elif method == 'spectral':\n",
    "            # Spectral clustering\n",
    "            clustering = SpectralClustering(n_clusters=n_clusters, random_state=seed, \n",
    "                                          affinity='nearest_neighbors', n_neighbors=min(10, X_reduced.shape[0]-1))\n",
    "            labels = clustering.fit_predict(X_reduced)\n",
    "            print(f\"Spectral clustering completed with {n_clusters} clusters\")\n",
    "            \n",
    "        elif method == 'dbscan':\n",
    "            # DBSCAN - automatically determines number of clusters\n",
    "            # Estimate eps using k-distance\n",
    "            k = min(5, X_reduced.shape[0] - 1)\n",
    "            neighbors = NearestNeighbors(n_neighbors=k)\n",
    "            neighbors_fit = neighbors.fit(X_reduced)\n",
    "            distances, indices = neighbors_fit.kneighbors(X_reduced)\n",
    "            distances = np.sort(distances[:, k-1], axis=0)\n",
    "            eps = np.percentile(distances, 90)  # Use 90th percentile as eps\n",
    "            \n",
    "            clustering = DBSCAN(eps=eps, min_samples=max(2, X_reduced.shape[0] // 20))\n",
    "            labels = clustering.fit_predict(X_reduced)\n",
    "            n_clusters_found = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            print(f\"DBSCAN clustering completed with {n_clusters_found} clusters (eps={eps:.3f})\")\n",
    "            \n",
    "        elif method == 'numpy_kmeans':\n",
    "            # Simple numpy K-means implementation\n",
    "            labels = simple_kmeans_numpy(X_reduced, n_clusters, seed=seed)\n",
    "            print(f\"Numpy K-means clustering completed with {n_clusters} clusters\")\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown clustering method: {method}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Clustering method '{method}' failed with error: {e}\")\n",
    "        print(\"Falling back to simple distance-based clustering...\")\n",
    "        # Ultimate fallback: simple distance-based clustering\n",
    "        np.random.seed(seed)\n",
    "        centers = X_reduced[np.random.choice(X_reduced.shape[0], n_clusters, replace=False)]\n",
    "        distances = np.sqrt(((X_reduced - centers[:, np.newaxis])**2).sum(axis=2))\n",
    "        labels = np.argmin(distances, axis=0)\n",
    "\n",
    "    # t-SNE projection with adjusted perplexity\n",
    "    perplexity = min(30, max(5, X_reduced.shape[0] // 4))\n",
    "    print(f\"Using perplexity: {perplexity}\")\n",
    "    \n",
    "    try:\n",
    "        tsne = TSNE(\n",
    "            n_components=3, \n",
    "            perplexity=perplexity, \n",
    "            init='pca', \n",
    "            learning_rate='auto',\n",
    "            n_iter=1000, \n",
    "            random_state=seed,\n",
    "            n_jobs=1  # Force single-threaded to avoid issues\n",
    "        )\n",
    "        X_2d = tsne.fit_transform(X_reduced)\n",
    "        print(\"t-SNE projection completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"t-SNE failed with error: {e}\")\n",
    "        print(\"Falling back to PCA for 2D projection...\")\n",
    "        # Fallback: use PCA for 2D projection\n",
    "        pca_2d = PCA(n_components=2)\n",
    "        X_2d = pca_2d.fit_transform(X_reduced)\n",
    "\n",
    "    return X_2d, labels\n",
    "\n",
    "\n",
    "def plot_codebook_2d(vectors_2d, labels, codebook_id, save_dir=\"plots_silhouette\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1], c=labels, cmap='tab10', s=30, alpha=0.7)\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.title(f\"Codebook {codebook_id} — 2D Projection with Clusters\")\n",
    "    plt.xlabel(\"Dimension 1\")\n",
    "    plt.ylabel(\"Dimension 2\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add some statistics to the plot\n",
    "    n_clusters = len(set(labels))\n",
    "    plt.text(0.02, 0.98, f'Vectors: {len(vectors_2d)}\\nClusters: {n_clusters}', \n",
    "             transform=plt.gca().transAxes, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f\"codebook_{codebook_id}_clusters.png\"), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved plot for codebook {codebook_id}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Loading DAC model...\")\n",
    "    model = load_dac_model(device=\"cpu\")\n",
    "    print(\"Extracting codebook weights...\")\n",
    "    codebook_weights = get_codebook_weights(model)\n",
    "    \n",
    "    # Try different clustering methods in order of preference\n",
    "    clustering_methods = ['hierarchical', 'numpy_kmeans', 'spectral', 'dbscan']\n",
    "    \n",
    "    print(f\"Found {len(codebook_weights)} codebooks\")\n",
    "    for i, vectors in enumerate(codebook_weights):\n",
    "        print(f\"\\n=== Processing Codebook {i} ===\")\n",
    "        print(f\"Shape: {vectors.shape}\")\n",
    "        \n",
    "        success = False\n",
    "        for method in clustering_methods:\n",
    "            try:\n",
    "                print(f\"Trying clustering method: {method}\")\n",
    "                X_2d, labels = cluster_and_project(vectors, n_clusters=5, method=method)\n",
    "                plot_codebook_2d(X_2d, labels, codebook_id=i)\n",
    "                success = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Method '{method}' failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not success:\n",
    "            print(f\"All clustering methods failed for codebook {i}\")\n",
    "\n",
    "    print(\"\\nCompleted! Check the 'plots/' folder for visualizations.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Alternative approach: Set environment variable to avoid threading issues\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41432ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DAC model...\n",
      "Extracting codebook weights...\n",
      "Found 9 codebooks\n",
      "\n",
      "=== Processing Codebook 0 ===\n",
      "Shape: (1024, 8)\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "HDBSCAN found 2 clusters\n",
      "Silhouette Score: 0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP projection completed\n",
      "Saved plot for codebook 0\n",
      "\n",
      "=== Processing Codebook 1 ===\n",
      "Shape: (1024, 8)\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "HDBSCAN found 2 clusters\n",
      "Silhouette Score: 0.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP projection completed\n",
      "Saved plot for codebook 1\n",
      "\n",
      "=== Processing Codebook 2 ===\n",
      "Shape: (1024, 8)\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "HDBSCAN found 0 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP projection completed\n",
      "Saved plot for codebook 2\n",
      "\n",
      "=== Processing Codebook 3 ===\n",
      "Shape: (1024, 8)\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "HDBSCAN found 2 clusters\n",
      "Silhouette Score: 0.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP projection completed\n",
      "Saved plot for codebook 3\n",
      "\n",
      "=== Processing Codebook 4 ===\n",
      "Shape: (1024, 8)\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "HDBSCAN found 4 clusters\n",
      "Silhouette Score: 0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP projection completed\n",
      "Saved plot for codebook 4\n",
      "\n",
      "=== Processing Codebook 5 ===\n",
      "Shape: (1024, 8)\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "HDBSCAN found 3 clusters\n",
      "Silhouette Score: 0.079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP projection completed\n",
      "Saved plot for codebook 5\n",
      "\n",
      "=== Processing Codebook 6 ===\n",
      "Shape: (1024, 8)\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "HDBSCAN found 3 clusters\n",
      "Silhouette Score: 0.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP projection completed\n",
      "Saved plot for codebook 6\n",
      "\n",
      "=== Processing Codebook 7 ===\n",
      "Shape: (1024, 8)\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "HDBSCAN found 0 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP projection completed\n",
      "Saved plot for codebook 7\n",
      "\n",
      "=== Processing Codebook 8 ===\n",
      "Shape: (1024, 8)\n",
      "Processing 1024 vectors of dimension 8\n",
      "PCA reduced to 8 dimensions\n",
      "HDBSCAN found 2 clusters\n",
      "Silhouette Score: 0.048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP projection completed\n",
      "Saved plot for codebook 8\n",
      "\n",
      "Completed! Check the 'plots_hdbscan_umap/' folder for visualizations.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import dac\n",
    "import umap\n",
    "import hdbscan\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def load_dac_model(model_type=\"44khz\", device=\"cpu\"):\n",
    "    model_path = dac.utils.download(model_type=model_type)\n",
    "    model = dac.DAC.load(model_path)\n",
    "    return model.to(device)\n",
    "\n",
    "def get_codebook_weights(model):\n",
    "    return [quant.codebook.weight.detach().cpu().numpy() for quant in model.quantizer.quantizers]\n",
    "\n",
    "def cluster_and_project(vectors, n_clusters=5, seed=42, method='agglomerative_cosine'):\n",
    "    print(f\"Processing {vectors.shape[0]} vectors of dimension {vectors.shape[1]}\")\n",
    "    X = normalize(vectors, norm='l2')\n",
    "\n",
    "    # Reduce to up to 50 dims with PCA (for clustering stability)\n",
    "    n_components = min(50, X.shape[1], X.shape[0] - 1)\n",
    "    X_pca = PCA(n_components=n_components).fit_transform(X)\n",
    "    print(f\"PCA reduced to {X_pca.shape[1]} dimensions\")\n",
    "\n",
    "    # Clustering\n",
    "    try:\n",
    "        if method == \"agglomerative_cosine\":\n",
    "            clustering = AgglomerativeClustering(n_clusters=n_clusters, affinity='cosine', linkage='average')\n",
    "            labels = clustering.fit_predict(X_pca)\n",
    "            print(f\"Agglomerative (cosine) clustering completed with {n_clusters} clusters\")\n",
    "\n",
    "        elif method == \"hdbscan\":\n",
    "            clusterer = hdbscan.HDBSCAN(\n",
    "                metric='euclidean',  # or 'cosine' if you skip PCA\n",
    "                min_cluster_size=10,\n",
    "                min_samples=5,\n",
    "                prediction_data=True\n",
    "            )\n",
    "            labels = clusterer.fit_predict(X_pca)\n",
    "            n_clusters_found = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            print(f\"HDBSCAN found {n_clusters_found} clusters\")\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown clustering method: {method}\")\n",
    "\n",
    "        # Silhouette Score\n",
    "        try:\n",
    "            valid = labels != -1  # skip noise points in HDBSCAN\n",
    "            if valid.sum() >= 2:\n",
    "                score = silhouette_score(X_pca[valid], labels[valid])\n",
    "                print(f\"Silhouette Score: {score:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Silhouette score failed: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Clustering failed with error: {e}\")\n",
    "        labels = np.zeros(X.shape[0])\n",
    "\n",
    "    # UMAP (non-linear 2D or 3D projection)\n",
    "    try:\n",
    "        reducer = umap.UMAP(n_components=2, random_state=seed, metric='cosine')\n",
    "        X_proj = reducer.fit_transform(X)\n",
    "        print(\"UMAP projection completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"UMAP failed: {e}, falling back to t-SNE\")\n",
    "        X_proj = TSNE(n_components=2, perplexity=30, random_state=seed, n_iter=1000).fit_transform(X_pca)\n",
    "\n",
    "    return X_proj, labels\n",
    "\n",
    "def plot_codebook_2d(vectors_2d, labels, codebook_id, save_dir=\"plots_hdbscan_umap\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1], c=labels, cmap='tab10', s=30, alpha=0.8)\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.title(f\"Codebook {codebook_id} — UMAP + Clustering\")\n",
    "    plt.xlabel(\"Dim 1\")\n",
    "    plt.ylabel(\"Dim 2\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    plt.text(0.02, 0.98, f'Vectors: {len(vectors_2d)}\\nClusters: {n_clusters}', \n",
    "             transform=plt.gca().transAxes, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, f\"codebook_{codebook_id}_clusters.png\"), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved plot for codebook {codebook_id}\")\n",
    "\n",
    "def main():\n",
    "    print(\"Loading DAC model...\")\n",
    "    model = load_dac_model(device=\"cpu\")\n",
    "    print(\"Extracting codebook weights...\")\n",
    "    codebook_weights = get_codebook_weights(model)\n",
    "    print(f\"Found {len(codebook_weights)} codebooks\")\n",
    "\n",
    "    for i, vectors in enumerate(codebook_weights):\n",
    "        print(f\"\\n=== Processing Codebook {i} ===\")\n",
    "        print(f\"Shape: {vectors.shape}\")\n",
    "\n",
    "        # Try HDBSCAN first, fall back to agglomerative\n",
    "        for method in ['hdbscan', 'agglomerative_cosine']:\n",
    "            try:\n",
    "                X_2d, labels = cluster_and_project(vectors, n_clusters=5, method=method)\n",
    "                plot_codebook_2d(X_2d, labels, codebook_id=i)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Method '{method}' failed: {e}\")\n",
    "                continue\n",
    "\n",
    "    print(\"\\nCompleted! Check the 'plots_hdbscan_umap/' folder for visualizations.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "    os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
